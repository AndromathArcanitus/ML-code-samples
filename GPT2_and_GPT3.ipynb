{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxAKSWJX2v2GIh0F4y/LN9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndromathArcanitus/ML-code-samples/blob/main/GPT2_and_GPT3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6fUe1Vbr5uC",
        "outputId": "f2750bc8-44f5-4b61-b763-9348d463fdac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.7 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import openai\n",
        "except:\n",
        "    !pip install openai\n",
        "    import openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key=\"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\""
      ],
      "metadata": {
        "id": "Z0mY24HwVUhc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "os.environ['OPENAI_API_KEY'] =\"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\"\n",
        "print(os.getenv('OPENAI_API_KEY'))\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8QOP2NlVY54",
        "outputId": "87966a34-dc8b-402f-ca3d-033127ce744b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=\"Original: She no went to the market.\\nStandard American English:\",\n",
        "    temperature=0,\n",
        "    max_tokens=60,\n",
        "    top_p=1.0,\n",
        "    frequency_penalty=0.0,\n",
        "    presence_penalty=0.0,\n",
        "    stop=[\"\\n\"]\n",
        ")"
      ],
      "metadata": {
        "id": "bAw1JLHTVw_Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#displaying the response object\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJFPXduuV3Vx",
        "outputId": "5ad76526-e15f-4009-b3d3-01d08d856404"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \" She didn't go to the market.\"\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1685941317,\n",
            "  \"id\": \"cmpl-7NwdppWTBsCWUQqmHxta8GuizrRje\",\n",
            "  \"model\": \"davinci\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 8,\n",
            "    \"prompt_tokens\": 14,\n",
            "    \"total_tokens\": 22\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieving the value of \"text\" in the dicionary\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A5DVl8dV5GW",
        "outputId": "5750a330-8a4c-4089-8eb0-76b5119b9c4b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " She didn't go to the market.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=\"Original: She no went to the market.\\n French with no contractions:\",\n",
        "    temperature=0, \n",
        "    max_tokens=60,\n",
        "    top_p=1.0,\n",
        "    frequency_penalty=0.0,\n",
        "    presence_penalty=0.0,\n",
        "    stop=[\"\\n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-EKwPqfV-Th",
        "outputId": "da272758-d5df-47db-95d6-be61ad3d0570"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Elle n'est pas allÃ©e au marchÃ©.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "    engine=\"davinci-instruct-beta\",\n",
        "    prompt=\"Write a plan of actions based on these instructions:\\n\\nStart Internet Explorer.\\nYou need to eventually click on the advanced tab.\\nBut before that, click on the Internet options on the tools menu.\\nAfter the click on the advanced tab, click to clear or select the enable\\npersonalized favorite menu check box.\\n\\n\\nACTIONS:\",\n",
        "    temperature=0,\n",
        "    max_tokens=120,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVBUOIX-WA49",
        "outputId": "01bd214a-7799-4841-e0ae-57ae58531214"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Start Internet Explorer.\n",
            "2. Click on the tools menu.\n",
            "3. Click on the Internet options.\n",
            "4. Click on the advanced tab.\n",
            "5. Click to clear or select the enable personalized favorite menu check box.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=\"Back to Future: ğŸ‘¨ğŸ‘´ğŸš—ğŸ•’\\nBatman: ğŸ¤µğŸ¦‡\\nTransformers: ğŸš—ğŸ¤–\\nWonder Woman: ğŸ‘¸ğŸ»ğŸ‘¸ğŸ¼ğŸ‘¸ğŸ½ğŸ‘¸ğŸ¾ğŸ‘¸ğŸ¿\\nWinnie the Pooh: ğŸ»ğŸ¼ğŸ»\\nThe Godfather: ğŸ‘¨ğŸ‘©ğŸ‘§ğŸ•µğŸ»â€â™‚ï¸ğŸ‘²ğŸ’¥\\nGame of Thrones: ğŸ¹ğŸ—¡ğŸ—¡ğŸ¹\\nSpider-Man:\",\n",
        "    temperature=0.8,\n",
        "    max_tokens=60,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    stop=[\"\\n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yui9obn5WENI",
        "outputId": "64c563c1-ca92-475a-fec8-e483a967b3b4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ğŸ•·ğŸ•¸ğŸ•¹\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=\"Back to Future: ğŸ‘¨ğŸ‘´ğŸš—ğŸ•’\\nBatman: ğŸ¤µğŸ¦‡\\nTransformers: ğŸš—ğŸ¤–\\nWonder Woman: ğŸ‘¸ğŸ»ğŸ‘¸ğŸ¼ğŸ‘¸ğŸ½ğŸ‘¸ğŸ¾ğŸ‘¸ğŸ¿\\nWinnie the Pooh: ğŸ»ğŸ¼ğŸ»\\nThe Godfather: ğŸ‘¨ğŸ‘©ğŸ‘§ğŸ•µğŸ»â€â™‚ï¸ğŸ‘²ğŸ’¥\\nGame of Thrones: ğŸ¹ğŸ—¡ğŸ—¡ğŸ¹\\nSpider-Man: ğŸ•·ğŸ•¸ğŸ•·ğŸ•¸\\nAvatar:\",\n",
        "    temperature=0.8,\n",
        "    max_tokens=60,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    stop=[\"\\n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "id": "4t_wujRMWNfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=\"##### Translate this function  from Python into Javascript\\n### Python\\n    \\n    def predict_proba(X: Iterable[str]):\\n        return np.array([predict_one_probas(tweet) for tweet in X])\\n    \\n### Javascript\\n    \\n    function predict_proba(X: Iterable[str]):\\n        return np.array([predict_one_probas(tweet) for tweet in X])\\n\\n# Now we can use the function in Javascript\\n%%\",\n",
        "    temperature=0,\n",
        "    max_tokens=54,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    stop=[\"###\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p-_RROvWR0w",
        "outputId": "45186283-6707-41a6-c981-a42be91aac22"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time\n",
            "predict_proba(X)\n",
            "# Output:\n",
            "# [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4kgo3JB85YK",
        "outputId": "fc06ec53-56a1-4a62-f170-0f79d716c40d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"length\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"time\\npredict_proba(X)\\n# Output:\\n# [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0\"\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1685941603,\n",
            "  \"id\": \"cmpl-7NwiRvpFqUx9mtL3pWumOTvWVaaGL\",\n",
            "  \"model\": \"davinci\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 54,\n",
            "    \"prompt_tokens\": 139,\n",
            "    \"total_tokens\": 193\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=\"This is a tweet sentiment classifier\\nTweet: \\\"I loved the new Batman movie!\\\"\\nSentiment: Positive\\n###\\nTweet: \\\"I hate it when my phone battery dies\\\"\\nSentiment: Negative\\n###\\nTweet: \\\"My day has been ğŸ‘\\\"\\nSentiment: Positive\\n###\\nTweet: \\\"This is the link to the article\\\"\\nSentiment: Neutral\\n###\\nTweet text\\n\\n\\n1. \\\"I loved the new Batman movie!\\\"\\n2. \\\"I hate it when my phone battery dies\\\"\\n3. \\\"My day has been ğŸ‘\\\"\\n4. \\\"This is the link to the article\\\"\\n5. \\\"This new music video blew my mind\\\"\\n\\n\\nTweet sentiment ratings:\\n1: Positive\\n2: Negative\\n3: Positive\\n4: Neutral\\n5: Positive\\n\\n\\n###\\nTweet text\\n\\n\\n1. \\\"I can't stand homework\\\"\\n2. \\\"This sucks. I'm bored ğŸ˜ \\\"\\n3. \\\"I can't wait for Halloween!!!\\\"\\n4. \\\"My cat is adorable â¤ï¸â¤ï¸\\\"\\n5. \\\"I hate chocolate\\\"\\n\\n\\nTweet sentiment ratings:\\n1.\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=60,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    stop=[\"###\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "id": "GDGM-NSiWUd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=\"This is a tweet sentiment classifier\\nSentence: \\\"What does semiotics mean?\\\"\\n\\nA: \",\n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    stop=[\"\\n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "id": "wbdIwzMfbM-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=\"Q: What does semiotics mean?\\nA: Semiotics is the study of signs and symbols.\\n\\nA: \",\n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    stop=[\"\\n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "id": "Gk26Z7TZwnB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=\"My second grader asked me what this passage means:\\n\\\"\\\"\\\"\\nJupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. It is named after the Roman god Jupiter.[19] When viewed from Earth, Jupiter can be bright enough for its reflected light to cast visible shadows,[20] and is on average the third-brightest natural object in the night sky after the Moon and Venus.\\n\\\"\\\"\\\"\\nI rephrased it for him, in plain language a second grader can understand:\\n\\\"\\\"\\\"\\n\",\n",
        "    temperature=0.5,\n",
        "    max_tokens=100,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0.2,\n",
        "    presence_penalty=0,\n",
        "    stop=[\"\\\"\\\"\\\"\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "id": "gZWrCzbWwqau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=\"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy. There are also loheckles, which are a grayish blue fruit and are very tart, a little bit like a lemon. Pounits are a bright green color and are more savory than sweet. There are also plenty of loopnovas which are a neon pink flavor and taste like cotton candy. Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\\n\\nPlease make a table summarizing the fruits from Goocrux\\n| Fruit | Color | Flavor |\\n| Neoskizzles | Purple | Sweet |\\n| Loheckles | Grayish blue | Tart |\\n\",\n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    stop=[\"\\n\\n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "id": "AiO1eCkZxSWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=\"def foo(n, k):\\naccum = 0\\nfor i in range(n):\\n    for l in range(k):\\n        accum += i\\nreturn accum\\n\\\"\\\"\\\"\\nThe time complexity of this function is\",\n",
        "    temperature=0,\n",
        "    max_tokens=64,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    stop=[\"\\n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "id": "e3p0USuxxW-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=\"A single column spreadsheet of industry names:\\n\\n\\nIndustry|\\nAccounting/Finance\\nAdvertising/Public Relations\\nAerospace/Aviation\\nArts/Entertainment/Publishing\\nAutomotive\\nBanking/Mortgage\\nBusiness Development\\nBusiness Opportunity\\nClerical/Administrative\\nConstruction/Facilities\\nConsumer Goods\\nCustomer Service\\nEducation/Training\\nEnergy/Utilities\\nEngineering\\nGovernment/Military\\nGreen\\n\\n\\n###\\n\\n\\nA spreadsheet of top science fiction movies and the year of release:\\n\\n\\nTitle|Year\\nStar Wars|1977\\nJaws|1975\\nThe Exorcist|1973\\nET|1982\\nAliens|1986\\nTerminator|1984\\nBlade Runner|1982\\nThe Thing|1982\\nJurassic Park|1993\\nThe Matrix|1999\\n\\n\\n###\\n\\n\\nA spreadsheet of hurricane and tropical storm counts with 13 columns:\\n\\n\\n\\\"Month\\\"| \\\"Average\\\"| \\\"2005\\\"| \\\"2006\\\"| \\\"2007\\\"| \\\"2008\\\"| \\\"2009\\\"| \\\"2010\\\"| \\\"2011\\\"| \\\"2012\\\"| \\\"2013\\\"| \\\"2014\\\"| \\\"2015\\\"\\n\\\"May\\\"|  0.1|  0|  0| 1| 1| 0| 0| 0| 2| 0|  0|  0  \\n\\\"Jun\\\"|  0.5|  2|  1| 1| 0| 0| 1| 1| 2| 2|  0|  1\\n\\\"Jul\\\"|  0.7|  5|  1| 1| 2| 0| 1| 3| 0| 2|  2|  1\\n\\\"Aug\\\"|  2.3|  6|  3| 2| 4| 4| 4| 7| 8| 2|  2|  3\\n\\\"Sep\\\"|  3.5|  6|  4| 7| 4| 2| 8| 5| 2| 5|  2|  5\\n\\\"Oct\\\"|  2.0|  8|  0| 1| 3| 2| 5| 1| 5| 2|  3|  0\\n\\\"Nov\\\"|  0.5|  3|  0| 0| 1| 1| 0| 1| 0| 1|  0|  1\\n\\\"Dec\\\"|  0.0|  1|  0| 1| 0| 0| 0| 0| 0| 0|  0|  1\\n    \\n###\\n\\n\\nA single column spreadsheet of days of the week:\\n\\n\\nDay|\\nMonday\\nTuesday\\nWednesday\\nThursday\\nFriday\\nSaturday\\nSunday\\n\\n\\n###\\n\\n\\nA two column spreadsheet of computer languages and their difficulty level:\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=60,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    stop=[\"/n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA6xgh6NxbHA",
        "outputId": "38c936f7-ba94-434a-e66f-ef437515b775"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Language|Difficulty\n",
            "C|Easy\n",
            "Java|Easy\n",
            "C++|Easy\n",
            "C#|Easy\n",
            "VB.NET|Easy\n",
            "JavaScript|Easy\n",
            "PHP|Easy\n",
            "Perl|Easy\n",
            "Python|Easy\n",
            "Ruby|Easy\n",
            "VB|Easy\n",
            "ASP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p16dreUA9bTN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}